# 가상 메모리

- 운영체제는 CPU에서 당장 수행해야 할 부분만을 메모리에 올려놓고 그렇지 않은 부분은 디스크의 스왑 영역에 내려놓았다가 필요해지면 메모리에 올라가 있는 부분과 교체하는 방식을 사용
  - 프로그램이 물리적 메모리를 고려할 필요 없이 자기 자신만이 메모리를 사용하는 것처럼 가정해 프로그램하는 것을 지원한다.

- 가상 메모리 : 프로그램은 0번지부터 시작하는 자기 자신만의 메모리 주소 공간을 가정할 수 있는데 이 메모리 공간을 가상 메모리라고 한다.
  - 가상 메모리는 프로세스마다 각각 0번지부터의 주소 공간을 가지게 되며 이들 공간 중 일부는 물리적 메모리에 적재되고 일부는 디스크의 스왑 영역에 존재하게 된다. 

- 프로세스의 주소 공간을 메모리로 적재하는 단위에 따라 가상 메모리 기법은 요구 페이징 방식과 요구 세그먼테이션 방식으로 구현
  - 대부분의 경우 요구 페이징 방식을 사용하며 요구 세그먼테이션 방식을 사용하는 경우는 대개 페이지드 세그먼테이션 기법을 사용하는 경우

### 1. 요구 페이징

- 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라 당장 사용될 페이지만을 올리는 방식
- 특정 페이지에 대해 CPU의 요청이 들어온 후에야 해당 페이지를 메모리에 적재
- 메모리 사용량이 감소하고 프로세스 전체를 메모리에 올리는 데 소요되는 입출력 오버헤드도 줄어듬
- 사용되지 않을 주소 영역에 대한 입출력까지 수행하던 기존 방식에 비해 응답시간을 단축시킬 수 있으며 시스템이 더 많은 프로세스를 수용할 수 있게 해줌
- 프로그램이 물리적 메모리의 용량 제약을 벗어날 수 있도록 해줌
  - 특정 프로세스를 구성하는 페이지 중에서 어떤 페이지가 메모리에 존재하고 어떤 페이지가 메모리에 존재하지 않는지 구별하기 위한 방안 필요
- 유효-무효 비트를 두어 각 페이지가 메모리에 존재하는지 표시
  - 각 프로세스를 구성하는 모든 페이지에 대해 존재해야 하므로 페이지 테이블의 각 항목별로 저장됨
  - 유효-무효 비트의 값이 무효인 경우는 페이지가 현재 메모리에 없는 경우뿐만 아니라 그 페이지가 속한 주소 영역을 프로세스가 사용하지 않는 경우도 있음
  - CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 유효-무효 비트가 무효로 세팅되어 있는 경우를 '페이지 부재'가 일어났다고 함

#### 요구 페이징의 페이지 부재 처리

- CPU가 무효 페이지에 접근하면 주소 변환을 담당하는 하드웨어인 MMU가 페이지 부재 트랩을 발생시키게 된다.
- CPU의 제어권이 커널모드로 전환되고 운영체제의 페이지 부재 처리루틴이 호출된다.
  - 부재 상태의 페이지를 메모리에 적재하기에 앞서 해당 페이지에 대한 접근이 적법한지를 먼저 체크한다.
  - 사용되지 않는 주소 영역에 속한 페이지에 접근하려 했거나 해당 페이지에 대한 접근 권한 위반을 했을 경우에는 해당 프로세스를 종료시킨다
- 해당 페이지에 대한 접근이 적법한 것으로 판명된 경우 물리적 메모리에서 비어 있는 프레임이 없다면 기존에 메모리를 올라와 있는 페이지 중 하나를 디스크로 스왑 아웃 시킨다.
- 요청된 페이지를 디스크로부터 메모리로 적재하기까지는 오랜 시간이 소요되므로 페이지 부재를 발생시킨 프로세스는 CPU를 째앗기고 봉쇄 상태가 된다.
- 현재까지 수행되던 CPU 레지스터 상태 및 프로그램 카운터값을 프로세스 제어블록에 저장해둠으로써 나중에 이 프로세스가 다시 CPU를 할당받았을 때 정확히 같은 상태에서 다음 명령을 수행할 수 있도록 한다.
- 디스크 입출력이 완료되어 인터럽트가 발생하면 페이지 테이블에서 해당 페이지의 유효-무효 비트를 유효로 설정하고, 봉쇄되었던 프로세스를 준비 큐로 이동시킨다.
- 이 프로세스가 다시 CPU를 할당받으면 프로세스 제어블록에 저장해두었던 값을 복원시켜 이전에 중단되었던 명령부터 실행을 재개한다.



#### 요구 페이징의 성능

- 가장 크게 영향을 미치는 요소는 페이지 부재의 발생 빈도

  - 페이지 부재가 일어나면 요청된 페이지를 디스크로부터 메모리로 읽어오는 막대한 오버헤드가 발생하기 때문

- 페이지 부재가 적게 발생할수록 요구 페이징의 성능은 향상될 수 있음

- 유효 접근 시간 = (1-P) * 메모리 접근 시간 

  ​							+ P*(페이지 부재 발생 처리 오버헤드

  ​							+메모리에 빈 프레임이 없는 경우 스왑 아웃 오버헤드

  ​							+요청된 페이지의 스왑 인 오버헤드

  ​							+프로세스의 재시작 오버헤드)

- 페이지 부재 발생 비율 : 0<=P<=1

  P=0 : 페이지 부재가 한번도 일어나지 않은 경우

  P=1 : 모든 참조 요청에서 페이지 부재가 발생한 경우



### 2. 페이지 교체

- 페이지 교체 : 메모리에 올라와 있는 페이지 중 하나를 디스크로 스왑 아웃 시켜 메모리에 빈 공간을 확보하는 작업
- 교체 알고리즘 : 페이지 교체를 할 때에 어떠한 프레임에 있는 페이지를 쫓아낼 것인지 결정하는 알고리즘
  - 페이지 부재율을 최소화하는 것이 목표
  - 따라서 가까운 미래에 참조될 가능성이 가장 적은 페이지를 선택해서 내쫓는 것이 성능을 향상시킬 수 있는 방안
  - 주어진 페이지 참조열에 대해 페이지 부재율을 계산함으로써 평가할 수 있음
  - 페이지 참조열 : 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것
  - 해당 번호의 페이지가 메모리에 이미 올라와 있으면 메모리에서 적중되었다고 하고, 메모리에 없는 경우에는 페이지 부재가 발생했다고 한다.



#### 1) 최적 페이지 교체

- 페이지 부재율을 최소화하기 위해서는 페이지 교체 시 물리적 메모리에 조재하는 페이지 중 가장 먼 미래에 참조될 페이지를 쫓아내면 된다.
- 이러한 최적의 알고리즘을 빌레디의 최적 알고리즘, 또는 MIN, OPT 등의 이름으로 부른다.
- 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고 있다는 전제 하에 알고리즘을 운영하므로 실제 시스템에서 온라인으로 사용할 수 있는 알고리즘은 아님. -> 오프라인 알고리즘
- 어떠한 알고리즘을 사용하는 경우보다도 가장 적은 페이지 부재율을 보장하므로 다른 알고리즘의 성능에 대한 상한선 제공

#### 2) 선입선출 알고리즘

- 페이지 교체 시 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫓음
- 페이지의 향후 참조 가능성을 고려하지 않고 물리적 메모리에 들어온 순서대로 내쫓을 대상을 선정하기 때문에 비효율적인 상황이 발생할 수 있음
- FIFO 알고리즘에서 메모리를 증가시켰음에도 페이지 부재가 오히려 늘어나는 상황을 FIFO의 이상 현상이라고 부름

#### 3) LRU 알고리즘

- 시간 지역성 : 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질
- 페이지 교체 시 가장 오래전에 참조가 이루어진 페이지를 내쫓음(참조 시점이 가장 오래된 페이지를 교체)

#### 4)LFU 알고리즘

- 페이지의 참조 횟수로 교체시킬 페이지를 결정
- 물리적 메모리 내에 존재하는 페이지 중 과거에 참조 횟수가 가장 적었던 페이지를 쫓아내고 그 자리에 새로 참조될 페이지 적재
- 최저 참조 횟수를 가진 페이지가 여러 개 존재하는 경우 임의로 선정
- 성능 향상을 위해서는 최저 참조 횟수를 가진 페이지들 중 상대적으로 더 오래전에 참조된 페이지를 쫓아내도록 구현하는 것이 효율적
- Incache-LFU : 페이지가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트하는 방식
- Perfect-LFU : 메모리에 올라와 있는지 여부와 상관 없이 그 페이지의 과거 총 참조 횟수를 카운트하는 방식
  - 참조 횟수를 정확히 반영할 수 있음
  - 메모리에서 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하기 때문에 상대적으로 오버헤드가 큼
- LRU 알고리즘보다 오랜 시간 동안의 참조기록을 반영할 수 있음
- 시간에 따른 페이지 참조의 변화를 반영하지 못하고 LRU에 비해 구현이 복잡

#### 5) 클럭 알고리즘

- LRU와 LFU 알고리즘은 페이지의 참조 시각 및 참조 횟수를 소프트웨어적으로 유지하고 비교해야 하므로 알고리즘의 운영에 시간적인 오버헤드 발생
- 하드웨어적인 지원을 통해 이와 같은 알고리즘의 운영 오버헤드를 줄인 방식
- LRU를 근사시킨 알고리즘으로 NUR(Not Used Recently) 또는 NRU(Not Recently used) 알고리즘이라고도 불림
- 오랫동안 참조되지 않은 페이지 중 하나를 교체
- 최근에 참조되지 않은 페이지를 교체 대상으로 선정한다는 측면에서 LRU와 유사하지만 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하지는 못한다는 점에서 LRU를 근사시킨 알고리즘으로 볼 수 있음
- 하드웨어적인 지원으로 동작하기 때문에 LRU에 비해 페이지의 관리가 훨씬 빠르고 효율적으로 이루어짐
- 교체할 페이지를 선정하기 위해 페이지 프레임의 참조비트를 순차적으로 조사
- 참조비트는 각 프레임마다 하나씩 존재하며 그 프레임 내의 페이지가 참조될 때 하드웨어에 의해 1로 자동 세팅
- 참조비트가 1인 페이지는 0으로 바꾼 후 그냥 지나가고 참조비트가 0인 페이지는 교체
- 최근에 참조가 일어나지 않은 페이지를 교체하는 알고리즘
- 적어도 시곗바늘이 한바퀴를 도는 데 소요되는 시간만큼 페이지를 메모리에 유지시켜둠으로써 페이지 부재율을 줄이도록 설계되었기 때문에 이 알고리즘을 2차 기회 알고리즘이라고도 부름



### 3. 페이지 프레임의 할당

각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지

- 균등할당 : 모든 프로세스에게 페이지 프레임을 균일하게 할당
- 비례할당 : 프로세스의 크기에 비례해 페이지 프레임 할당
  - 프로세스의 크기가 모두 균일하지 않다는 점에 착안한 방식으로 프로세스의 크기를 고려한 균등할당 방식
- 우선순위 할당 : 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당
  - 프로세스 중 당장 CPU에서 실행될 프로세스와 그렇지 않은 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당하는 방식
- CPU에서 명령을 실행할 때에는 일반적으로 코드, 데이터, 스택 등 각기 다른 영역을 참조하기 때문에 여러 페이지를 동시에 참조
- 프로세스를 정상적으로 수행하기 위해서는 적어도 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야 함
- 반복문을 실행 중인 프로세스의 경우 반복문을 구성하는 페이지들을 한꺼번에 메모리에 올려놓는 것이 유리
- 프로세스에게 최소한으로 필요한 메모리의 양은 시간에 따라 다를 수 있음
- 종합적인 상황을 고려해서 각 프로세스에 할당되는 페이지 프레임 수를 결정할 필요가 있으며 경우에 따라서는 일부 프로세스에게 메모리를 할당하지 않는 방식으로 나머지 프로세스들에게 최소한의 메모리 요구량을 충족시킬 수 있어야 함

### 4. 전역교체와 지역교체

- 전역교체 : 모든 페이지 프레임이 교체 대상이 될 수 있는 방법
  - 프로세스마다 메모리를 할당하는 것이 아니라 전체 메모리를 각 프로세스가 공유해서 사용하고 교체 알고리즘에 근거해서 할당되는 메모리 양이 가변적으로 변하는 방법
  - LRU, LFU, 클럭 등의 알고리즘을 물리적 메모리 내에 존재하는 전체 페이지 프레임들을 대상으로 적용하는 경우
- 지역교체 : 현재 수행중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정할 수 있는 방법
  - 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제
  - LRU, LFU 등의 알고리즘을 프로세스별로 독자적으로 운영할 때는 지역교체 방법이 됨



### 5. 스레싱

- 스레싱 : 집중적으로 참조되는 페이지들의 집합을 메모리에 한꺼번에 적재하지 못하면 페이지 부재율이 크게 상승해 CPU 이용률이 급격히 떨어짐
- CPU 이용률이 낮을 경우 운영체제는 MPD를 높이게 됨
  - MPD가 과도하게 높아지면 각 프로세스에게 할당되는 메모리의 양이 지나치게 감소
  - 각 프로세스는 그들이 원활하게 수행되기 위해 필요한 최소한의 페이지 프렝미도 할당받지 못하는 상태가 되어 페이지 부재가 빈번히 발생
  - 페이지 부재가 발생하면 디스크 I/O 작업을 수반하므로 문맥교환을 통해 다른 프로세스에게 CPU가 이양
  - 다른 프로세스 역시 할당받은 메모리 양이 지나치게 적으면 페이지 부재가 발생
  - 또 다른 프로세스에게 CPU 할당
  - 준비 큐에 있는 모든 프로세스에게 CPU가 한 차례씩 할당되었는데도 모든 프로세스가 다 페이지 부재를 발생시켜 시스템은 페이지 부재를 처리하느라 매우 분주해지고 CPU의 이용률은 급격히 감소
  - 운영체제는 메모리에 올라와 있는 프로세스의 수가 적어 이러한 현상이 발생했다고 판단하고 MPD를 높이기 위해 또 다른 프로세스를 메모리에 추가
  - 이로 인해 프로세스당 항당된 프레임의 수가 더욱 감소하고 페이지 부재는 더욱 빈번히 발생
  - 프로세스들은 서로의 페이지를 교체하며 스왑 인과 스왑 아웃을 지속적으로 발생시키고 CPU는 대부분의 시간에 일을 하지 않음

-  MPD를 적절히 조절 해 CPU 이용률을 높여야 함



#### 1) 워킹셋 알고리즘

- 지역성 집합 : 프로세스는 일정 시간동안 특정 주소 영역을 집중적으로 참조하는 경향이 있는데 이렇게 집중적으로 참조되는 페이지들의 집합
- 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘
- 프로세스가 일정 시간 동안 원활히 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합을 워킹셋으로 정의하고 프로세스의 워킹셋을 구성하는 페이지들이 한꺼번에 메모리에 돌라갈 수 있는 경우에만 그 프로세스에게 메모리를 할당
- 그렇지 않을 경우 프로세스에게 할당된 페이지 프레임들을 모두 반납시킨 후 그 프로세스의 주소 공간 전체를 디스크로 스왑 아웃
- MPD를 조절하고 스레싱 방지
- 메모리에 올라와 있는 프로세스들의 워킹셋 크기의 합이 프레임의 수보다 클 경우 일부 프로세스를 스왑 아웃시켜서 남은 프로세스의 워킹셋이 메모리에 모두 올라가는 것 보장 -> MPD를 줄이는 효과
- 프로세스들의 워킹셋을 모두 할당한 후에도 프레임이 남을 경우 스왑 아웃시켰던 프로세스를 다시 메모리에 올려 워킹셋을 할당함으로써 MPD 증가
- CPU 이용률을 높게 유지하면서 MPD를 적절히 조절해 스레싱 방지
- 시스템의 성능을 향상시키기 위해서는 프로세스들의 지역성 집합을 효과적으로 탐지할 수 있는 윈도우 크기를 결정하는 것이 중요
- 워킹셋의 크기는 시간에 따라 변함
  - 프로세스가 메모리를 많이 필요로 할 때에는 많이 할당하고 적게 필요로 할 떄에는 적게 할당하는 일종의 동적인 프레임 할당 기능까지 수행

#### 2) 페이지 부재 빈도 알고리즘

- 프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 동적으로 조절
- 어떤 프로세스의 페이지 부재율이 시스템에서 미리 정해놓은 상한값을 넘게 되면 이 프로세스에 할당된 프레임의 수가 부족하다고 판단하여 이 프로세스에게 프레임을 추가로 더 할당
  -  추가로 할당할 빈 프레임이 없다면 일부 프로세스를 스왑 아웃시켜 메모리에 올라가 있는 프로세스의 수 조절
- 프로세스의 부재율이 하한값 이하로 떨어지면 이 프로세스에게 필요 이상으로 많은 프레임이 할당된 것으로 간주해 할당된 프레임의 수를 줄임
- 이러한 방식으로 메모리 내에 존재하는 모든 프로세스에 필요한 프레임을 다 할당한 후에도 프레임이 남는 경우 스왑 아웃되었던 프로세스에게 프레임을 할당함으로써 MPD를 높임
